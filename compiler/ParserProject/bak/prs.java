/**
 *  Jacob Malimban
 *
 *  Recieves tokens from lex()
 */
import java.io.*;
import java.lang.Character;

public class prs {

/** /
	// definitions
	enum Token {
		INT_LIT, IDENT, ASSIGN_OP, ADD_OP, SUB_OP, MULT_OP, DIV_OP, LEFT_PAREN, RIGHT_PAREN, END_OF_LINE, END_OF_FILE
	}
/**/

	// variables
	static	Token nextToken;
	static	String fileName = "sourceStatements.txt";
	static	String line = null;

	public static void main(String[] args) {

		try {
			// print to file?
			if(true) {
				PrintStream o = new PrintStream(new File("parseOut.txt"));
				System.setOut(o);
			}
		} catch (FileNotFoundException e) {}


		for(int i = 0; i < 80; i++)
			System.out.print("*");				// formatting
		System.out.println("\nJacob M. Student, CSCI4200, Fall 2019, Parser");
		for(int i = 0; i < 80; i++)
			System.out.print("*");
		System.out.println();

		// try creating readers
		try {
			FileReader fReader = new FileReader(fileName);
			BufferedReader bReader = new BufferedReader(fReader);

			// read input line by line, and build lexemes in each line
			while((line = bReader.readLine()) != null) {
				System.out.println("Parsing the statement: "+line);
				LexicalAnalyzer.line = line;
				LexicalAnalyzer.EOL();
				nextToken = LexicalAnalyzer.lex();

				tokenLogic();

/** /
				System.out.println("Input: " + line);
				getChar();

				for(char ch : line.toCharArray()) {
					LexicalAnalyzer.lex();
					if(nextToken == Token.END_OF_LINE)
						break;
				}
/**/
			}

			// end of file reached
			bReader.close();

			System.out.println("END_OF_FILE");

		} catch (Exception e) {
			System.out.println("Error - file unopenable or readers not initialized.");
		}
	}


	/**
	 *  Decides what to do with tokens
	 *  Guarantees EOL reached
	 *
	 */
	private static void tokenLogic() {
		while(nextToken != Token.END_OF_LINE) {
			switch(nextToken) {
				case INT_LIT:
					factor();
					break;
				case IDENT:
					factor();
					break;
				case ASSIGN_OP:
					assign();
					break;
				case ADD_OP:
					break;
				case SUB_OP:
					break;
				case MULT_OP:
					break;
				case DIV_OP:
					break;
				case LEFT_PAREN:
					factor();
					break;
				case RIGHT_PAREN:
					break;
				case END_OF_LINE:
					break;
				case END_OF_FILE:
					break;
			}
		}
		for(int i = 0; i < 80; i++)
			System.out.print("*");
		System.out.println();
	}


	/**
	 *  Parses string in the language generated by the rule:
	 *  id = <expr>
	 *
	 */
	private static void assign() {
		System.out.println("Enter <assign>");

		nextToken = LexicalAnalyzer.lex();

		expr();

		System.out.println("Exit <assign>");
	}

	/**
	 *  Parses strings in the language generated by the rule:
	 *  <expr> -> <term> { (+ | -) <term> }
	 *
	 */
	private static void expr() {
		System.out.println("Enter <expr>");

		// parse first term
		term();

		while(nextToken == Token.ADD_OP || nextToken == Token.SUB_OP) {
			nextToken = LexicalAnalyzer.lex();
			term();
		}
		System.out.println("Exit <expr>");
	}

	/**
	 *  Parses strings in language generated by the rule:
	 *  <term> -> <factor> { (* | /) <factor> }
	 *
	 */
	private static void term() {
		System.out.println("Enter <term>");

		factor();

		while(nextToken == Token.MULT_OP || nextToken == Token.DIV_OP) {
			nextToken = LexicalAnalyzer.lex();
			factor();
		}
		System.out.println("Exit <term>");
	}

	/**
	 *  Parses strings in the language generated by the rule:
	 *  <factor> -> id | int_const | ( <expr> )
	 *
	 */
	private static void factor() {
		System.out.println("Enter <factor>");

		// get next Token
		if(nextToken == Token.IDENT || nextToken == Token.INT_LIT)
			nextToken = LexicalAnalyzer.lex();
		else {
			if(nextToken == Token.LEFT_PAREN) {
				nextToken = LexicalAnalyzer.lex();
				expr();
				if(nextToken == Token.RIGHT_PAREN)
					nextToken = LexicalAnalyzer.lex();
				else
System.out.println("Error");					//error();
			}
		}
		System.out.println("Exit <factor>");
	}
}
